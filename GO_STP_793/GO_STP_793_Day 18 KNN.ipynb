{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "satisfied-estonia",
   "metadata": {},
   "source": [
    "<h1><center>K-Nearest Neighbour </center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deluxe-alexander",
   "metadata": {},
   "source": [
    "It is a supervised ML algorithm based on similarities.\n",
    "\n",
    "It stores complete data as training data and whenever we get new data , it checks for similarities from the available data.\n",
    "So when the new data appears we can classify it into our formed classes.\n",
    "\n",
    "This algo is Non-parametric i.e it does not make any assumption\n",
    "Also this is called Lazy learner i.e it does not learns, but just stores the training data and classify the new points according to the stored data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "treated-corporation",
   "metadata": {},
   "source": [
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amazing-album",
   "metadata": {},
   "source": [
    "# KNN Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dental-python",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "universal-correction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "iris.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "discrete-edinburgh",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3\n",
       "0    5.1  3.5  1.4  0.2\n",
       "1    4.9  3.0  1.4  0.2\n",
       "2    4.7  3.2  1.3  0.2\n",
       "3    4.6  3.1  1.5  0.2\n",
       "4    5.0  3.6  1.4  0.2\n",
       "..   ...  ...  ...  ...\n",
       "145  6.7  3.0  5.2  2.3\n",
       "146  6.3  2.5  5.0  1.9\n",
       "147  6.5  3.0  5.2  2.0\n",
       "148  6.2  3.4  5.4  2.3\n",
       "149  5.9  3.0  5.1  1.8\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(iris['data'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bronze-grammar",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df\n",
    "y = iris['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "excess-upper",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 4)\n",
      "\n",
      "(100,)\n",
      "\n",
      "(50, 4)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=0)\n",
    "\n",
    "print(x_train.shape)\n",
    "print()\n",
    "print(y_train.shape)\n",
    "print()\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fatty-program",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "electronic-trauma",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "earned-talent",
   "metadata": {},
   "source": [
    "# prediction and accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "sapphire-clause",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new = np.array([[5, 2.9, 1, 0.2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "colonial-consistency",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "['setosa']\n"
     ]
    }
   ],
   "source": [
    "prediction = knn.predict(x_new)\n",
    "print(prediction)\n",
    "print(iris['target_names'][prediction])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "warming-arnold",
   "metadata": {},
   "source": [
    "# accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "deluxe-prize",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16  0  0]\n",
      " [ 0 18  1]\n",
      " [ 0  1 14]]\n",
      "\n",
      "Accuracy is 96.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "y_pred = knn.predict(x_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print()\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy is\", acc*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "coral-fraud",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       0.95      0.95      0.95        19\n",
      "           2       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.96        50\n",
      "   macro avg       0.96      0.96      0.96        50\n",
      "weighted avg       0.96      0.96      0.96        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cr = classification_report(y_test, y_pred)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "later-functionality",
   "metadata": {},
   "source": [
    "## K-Fold Cross Validation Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabulous-ozone",
   "metadata": {},
   "source": [
    "it is a measure of ML algorithm's performance\n",
    "\n",
    "We make bathces of data and then we use different batches for testing and training and chceking if some batch is giving a better accuracy than others.\n",
    "\n",
    "E.g. we make 5 batches of our data\n",
    "\n",
    "we use the 1st batch as the test set and others as training set. And compute the accuarcy\n",
    "\n",
    "similarly we make 2nd, 3rd, 4th .. as the test set and then computer the accuracies.\n",
    "\n",
    "Lastly we take the average of these accuracies for two or more different ML algorithms and compare the two algorithms for the given dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "necessary-sunset",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "amber-cursor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "geological-channels",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "military-merchant",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = iris['data']\n",
    "y = iris['target']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "forbidden-generation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loose-durham",
   "metadata": {},
   "source": [
    "# For logistics regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "surgical-weather",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96666667 1.         0.93333333 0.96666667 1.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\harshit\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "lr_score = cross_val_score(LogisticRegression(), x, y)\n",
    "\n",
    "print(lr_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dependent-newark",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9733333333333334"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(lr_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usual-novelty",
   "metadata": {},
   "source": [
    "# Decision treee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "julian-front",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96666667 0.96666667 0.9        0.96666667 1.        ]\n",
      "96.00000000000001\n"
     ]
    }
   ],
   "source": [
    "dt_score = cross_val_score(DecisionTreeClassifier(), x, y)\n",
    "\n",
    "print(dt_score)\n",
    "\n",
    "print(np.average(dt_score)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comic-nightlife",
   "metadata": {},
   "source": [
    "# SVM score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "homeless-watts",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96666667 0.96666667 0.96666667 0.93333333 1.        ]\n",
      "\n",
      "96.66666666666666\n"
     ]
    }
   ],
   "source": [
    "svm_score = cross_val_score(SVC(), x, y)\n",
    "print(svm_score)\n",
    "\n",
    "print()\n",
    "\n",
    "print(np.average(svm_score)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungarian-chemistry",
   "metadata": {},
   "source": [
    "# K fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "temporal-album",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "crazy-sugar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KFold(n_splits=5, random_state=None, shuffle=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revised-uniform",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
